{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dae072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "df = pd.read_csv(\"corona_tested_006.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cf336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ac959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Ind_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the resultant (df) dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to understand numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93258076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for datatypes and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying the original dataset to another variable for further usage\n",
    "df1 = df.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Sex'] = df1['Sex'].replace('None', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Age_60_above'] = df1['Age_60_above'].replace('None', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b601549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['Age_60_above'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex_count = px.pie(df1['Sex'].value_counts().reset_index(),\n",
    "                                   names='index',\n",
    "                                   values='Sex',\n",
    "                                   title='Sex Distribution')\n",
    "\n",
    "# Show the chart\n",
    "Sex_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['Sex'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Cough_symptoms'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f66752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "#df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('True', 'TRUE')\n",
    "#df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('False', 'FALSE')\n",
    "df1['Cough_symptoms'] = df['Cough_symptoms'].replace({'True': 'TRUE', 'False': 'FALSE', 'None': np.nan, False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53748645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Cough_symptoms'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed58d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cough_symptoms_count = px.pie(df1['Cough_symptoms'].value_counts().reset_index(),\n",
    "                                   names='index',\n",
    "                                   values='Cough_symptoms',\n",
    "                                   title='Cough_symptoms Distribution')\n",
    "\n",
    "# Show the chart\n",
    "Cough_symptoms_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# replacing nan values with mode\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Perform imputation on the 'Annual_income' column\n",
    "df1['Cough_symptoms'] = imputer.fit_transform(df1[['Cough_symptoms']])\n",
    "\n",
    "# Verify the changes\n",
    "print(df1['Cough_symptoms'].isnull().sum())  # Should print 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f661a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in 'Cough_symptoms'\n",
    "Cough_symptoms_counts = df1['Cough_symptoms'].value_counts()\n",
    "\n",
    "#bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "Cough_symptoms_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Cough_symptoms')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of GENDER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa11469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Fever'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "df1['Fever'] = df1['Fever'].replace({'True': 'TRUE', 'False': 'FALSE', 'None': np.nan, False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a04ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in 'GENDER'\n",
    "Fever_counts = df1['Fever'].value_counts()\n",
    "\n",
    "#bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "Fever_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Fever')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of GENDER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing nan values with mode\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Perform imputation on the 'Annual_income' column\n",
    "df1['Fever'] = imputer.fit_transform(df1[['Fever']])\n",
    "\n",
    "# Verify the changes\n",
    "print(df1['Fever'].isnull().sum())  # Should print 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Sore_throat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52964828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "df1['Sore_throat'] = df1['Sore_throat'].replace({'True': 'TRUE', 'False': 'FALSE', 'None': np.nan, False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30407f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(subset=['Sore_throat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b89f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afed38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Shortness_of_breath'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c248fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "df1['Shortness_of_breath'] = df1['Shortness_of_breath'].replace({'True': 'TRUE', 'False': 'FALSE', False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c127d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Headache'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "df1['Headache'] = df1['Headache'].replace({'True': 'TRUE', 'False': 'FALSE', False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69808080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Known_contact'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "df1['Known_contact'] = df1['Known_contact'].replace({'True': 'TRUE', 'False': 'FALSE', 'nan': np.nan, False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['Cough_symptoms'] = df1['Cough_symptoms'].replace('None', np.nan)\n",
    "df1['Corona'] = df1['Corona'].replace({'True': 'TRUE', 'False': 'FALSE', 'NaN': np.nan, False: 'FALSE', True: 'TRUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Corona'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Corona'] = df1['Corona'].replace('other', 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aae7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in 'Corona'\n",
    "Corona_counts = df1['Corona'].value_counts()\n",
    "\n",
    "#bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "Corona_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Corona')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Corona')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Test_date'] = pd.to_datetime(df1['Test_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe95768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fdec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2940e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a83c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Extract the 'GENDER' column\n",
    "all_column = df1[['Cough_symptoms','Fever', 'Sore_throat','Shortness_of_breath','Headache','Known_contact']]\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # 'drop' to avoid multi-collinearity\n",
    "\n",
    "# Fit and transform the 'GENDER' column\n",
    "col_encoded = encoder.fit_transform(all_column)\n",
    "\n",
    "# Create a DataFrame with the one-hot encoded columns\n",
    "col_encoded_df = pd.DataFrame(col_encoded, columns=encoder.get_feature_names_out(['Cough_symptoms','Fever', 'Sore_throat','Shortness_of_breath','Headache','Known_contact']))\n",
    "\n",
    "# Replace the original 'GENDER' column with the one-hot encoded columns in df1\n",
    "df1 = pd.concat([df1.drop(['Cough_symptoms','Fever', 'Sore_throat','Shortness_of_breath','Headache','Known_contact'], axis=1), col_encoded_df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e335943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Test_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160135fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d02bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1022a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, and date components\n",
    "df1['Year'] = df1['Test_date'].dt.year\n",
    "df1['Month'] = df1['Test_date'].dt.month\n",
    "df1['Day'] = df1['Test_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59fcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['Test_date'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633928e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062931d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Corona' column\n",
    "df1['Corona_encoded'] = label_encoder.fit_transform(df1['Corona'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9252e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['Corona'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aaace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df1['Corona_encoded'].nunique()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba69537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Corona_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c70838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5754826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1.drop(['Corona_encoded'],axis=1)\n",
    "y = df1['Corona_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08916d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = X_train.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything other feature\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = correlation(X_train, 0.3)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ff237",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641668c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.drop(corr_features,axis=1)\n",
    "X_test.drop(corr_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b317df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43847f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class=LogisticRegression()\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94061e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09d070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#Imbalanced dataset so f1 score for 1 is 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689f4b7",
   "metadata": {},
   "source": [
    "# class_weight Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Corona_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight=dict({0:1,1:5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cwt = X_train\n",
    "y_train_cwt = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(class_weight=class_weight)\n",
    "classifier.fit(X_train_cwt,y_train_cwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c961da",
   "metadata": {},
   "source": [
    "# class_weight for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "logreg_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_classifier.fit(X_train_cwt, y_train_cwt)\n",
    "\n",
    "# Predict on the test set\n",
    "logreg_predictions = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, logreg_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, logreg_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, logreg_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores = cross_val_score(logreg_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Standard Deviation:\", cv_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efb052",
   "metadata": {},
   "source": [
    "# class_weight for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702cdad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the SVM model\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_classifier.fit(X_train_cwt, y_train_cwt)\n",
    "\n",
    "# Predict on the test set\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores_svm = cross_val_score(svm_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores_svm)\n",
    "print(\"Mean Accuracy:\", cv_scores_svm.mean())\n",
    "print(\"Standard Deviation:\", cv_scores_svm.std())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade5d43",
   "metadata": {},
   "source": [
    "# Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ost = X_train\n",
    "y_train_ost = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=0.75)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_ost, y_train_ost)\n",
    "\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train_ost)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a87eb9",
   "metadata": {},
   "source": [
    "# Oversampling for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee02d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "logreg_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_classifier.fit(X_train_ost, y_train_ost)\n",
    "\n",
    "# Predict on the test set\n",
    "logreg_predictions = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, logreg_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, logreg_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, logreg_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores = cross_val_score(logreg_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Standard Deviation:\", cv_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae655c25",
   "metadata": {},
   "source": [
    "# Oversampling technique for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the SVM model\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_classifier.fit(X_train_ost, y_train_ost)\n",
    "\n",
    "# Predict on the test set\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores_svm = cross_val_score(svm_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores_svm)\n",
    "print(\"Mean Accuracy:\", cv_scores_svm.mean())\n",
    "print(\"Standard Deviation:\", cv_scores_svm.std())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8c2b4",
   "metadata": {},
   "source": [
    "# SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d555cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smt = X_train\n",
    "y_train_smt = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8ae08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(sampling_strategy=0.75)\n",
    "X_train_resampled, y_train_resampled = smt.fit_resample(X_train_smt, y_train_smt)\n",
    "\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train_smt)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85af056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9906da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4726b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores = cross_val_score(rf_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Standard Deviation:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdcb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Count the occurrences of each unique value in the 'Predicted' column\n",
    "predicted_counts = results_df['Predicted'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(predicted_counts)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f75f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_test and predictions are your actual labels and predicted labels\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extracting values from the confusion matrix\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "# Total number of actual 0s and 1s\n",
    "total_actual_0s = true_negatives + false_negatives\n",
    "total_actual_1s = false_positives + true_positives\n",
    "\n",
    "# Total number of predicted 0s and 1s\n",
    "total_predicted_0s = true_negatives + false_positives\n",
    "total_predicted_1s = false_negatives + true_positives\n",
    "\n",
    "print(\"Total Actual 0s:\", total_actual_0s)\n",
    "print(\"Total Actual 1s:\", total_actual_1s)\n",
    "print(\"Total Predicted 0s:\", total_predicted_0s)\n",
    "print(\"Total Predicted 1s:\", total_predicted_1s)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d44df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "logreg_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_classifier.fit(X_train_smt, y_train_smt)\n",
    "\n",
    "# Predict on the test set\n",
    "logreg_predictions = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, logreg_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, logreg_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, logreg_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores = cross_val_score(logreg_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Standard Deviation:\", cv_scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the SVM model\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_classifier.fit(X_train_smt, y_train_smt)\n",
    "\n",
    "# Predict on the test set\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Perform cross-validation (optional)\n",
    "cv_scores_svm = cross_val_score(svm_classifier, X_test, y_test, cv=5)\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores_svm)\n",
    "print(\"Mean Accuracy:\", cv_scores_svm.mean())\n",
    "print(\"Standard Deviation:\", cv_scores_svm.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443724fc",
   "metadata": {},
   "source": [
    "### SMOTE Technique is not working for Logistic Regression and SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b52a89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
